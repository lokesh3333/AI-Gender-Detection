{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "2f76e6f5bf4b24e9c04440eafbf54f1debf382a522eafaa4ab9009d7f395ec89"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import cvlib as cv\n",
    "import time\n",
    "from flask import Flask, request, jsonify, render_template, Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = load_model('gender_detection.model')\n",
    "\n",
    "    # open webcam\n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    \n",
    "    classes = ['man','woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, frame = webcam.read()\n",
    "        # apply face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        face, confidence = cv.detect_face(frame)\n",
    "        \n",
    "        people = \"\"\n",
    "  \n",
    "\n",
    "        # loop through detected faces\n",
    "        for idx, f in enumerate(face):\n",
    "\n",
    "            # get corner points of face rectangle        \n",
    "            (startX, startY) = f[0], f[1]\n",
    "            (endX, endY) = f[2], f[3]\n",
    "\n",
    "            # draw rectangle over face\n",
    "            cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "\n",
    "            # crop the detected face region\n",
    "            face_crop = np.copy(frame[startY:endY,startX:endX])\n",
    "\n",
    "            if (face_crop.shape[0]) < 10 or (face_crop.shape[1]) < 10:\n",
    "                continue\n",
    "\n",
    "            # preprocessing for gender detection model\n",
    "            face_crop = cv2.resize(face_crop, (96,96))\n",
    "            face_crop = face_crop.astype(\"float\") / 255.0\n",
    "            face_crop = img_to_array(face_crop)\n",
    "            face_crop = np.expand_dims(face_crop, axis=0)\n",
    "\n",
    "            # apply gender detection on face\n",
    "            conf = model.predict(face_crop)[0] # model.predict return a 2D matrix, ex: [[9.9993384e-01 7.4850512e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "face, confidence = cv.detect_face(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True   [[[52 68 66]\n  [53 69 68]\n  [50 71 67]\n  ...\n  [51 58 55]\n  [50 60 56]\n  [50 60 56]]\n\n [[52 68 65]\n  [53 70 66]\n  [55 69 66]\n  ...\n  [46 59 55]\n  [50 60 55]\n  [50 60 55]]\n\n [[55 69 66]\n  [54 68 65]\n  [56 68 63]\n  ...\n  [48 60 56]\n  [48 60 55]\n  [48 60 55]]\n\n ...\n\n [[39 55 54]\n  [39 55 54]\n  [39 55 54]\n  ...\n  [15 29 28]\n  [15 29 28]\n  [15 29 28]]\n\n [[38 56 57]\n  [37 55 55]\n  [37 55 54]\n  ...\n  [15 29 28]\n  [15 29 28]\n  [15 29 28]]\n\n [[35 55 55]\n  [35 55 55]\n  [37 55 54]\n  ...\n  [15 29 28]\n  [15 29 28]\n  [15 29 28]]]\n"
     ]
    }
   ],
   "source": [
    "print(status,' ' ,frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}